{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7bbd59",
   "metadata": {},
   "source": [
    "# FIRE Data Transformation and Ingestion Patterns Analysis\n",
    "\n",
    "This notebook analyzes the example data files from the FIRE (Financial Instrument and Risk Engine) repository to understand:\n",
    "1. Common data structures\n",
    "2. Transformation patterns\n",
    "3. Data ingestion approaches\n",
    "\n",
    "First, let's import necessary libraries and load some example files.\n",
    "\n",
    "# FIRE Data Analysis\n",
    "\n",
    "This notebook analyzes the example files from the FIRE (Financial Regulatory) data model. We'll explore:\n",
    "\n",
    "1. Example JSON files and their structure\n",
    "2. Common data patterns\n",
    "3. Data transformations and validations\n",
    "4. Ingestion patterns and best practices\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Define paths\n",
    "FIRE_EXAMPLES_PATH = '/tmp/fire-repo/examples'\n",
    "examples = glob.glob(os.path.join(FIRE_EXAMPLES_PATH, '*.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798836da",
   "metadata": {},
   "source": [
    "## Loading Example Files\n",
    "\n",
    "Let's look at some example JSON files from the FIRE repository to understand their structure and patterns.\n",
    "\n",
    "## Analysis of FIRE Examples\n",
    "\n",
    "FIRE provides a rich set of example files demonstrating various financial instruments and their representation in the data model. Let's analyze these examples to understand:\n",
    "\n",
    "1. Common data structures\n",
    "2. Field patterns and relationships\n",
    "3. Data validation rules\n",
    "4. Best practices for ingestion\n",
    "\n",
    "First, let's load and examine some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da205340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# List all example JSON files\n",
    "example_files = glob.glob('/tmp/fire-repo/examples/*.json')\n",
    "print(f\"Found {len(example_files)} example files\")\n",
    "\n",
    "# Create a dictionary to store example data by type\n",
    "examples_by_type = {}\n",
    "\n",
    "# Load each example file and categorize by type\n",
    "for file_path in example_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        type_name = data.get('type', 'unknown')\n",
    "        if type_name not in examples_by_type:\n",
    "            examples_by_type[type_name] = []\n",
    "        examples_by_type[type_name].append({\n",
    "            'file': os.path.basename(file_path),\n",
    "            'data': data\n",
    "        })\n",
    "\n",
    "# Print summary of types\n",
    "print(\"\\nTypes of financial instruments found:\")\n",
    "for type_name, examples in examples_by_type.items():\n",
    "    print(f\"{type_name}: {len(examples)} examples\")\n",
    "\n",
    "# Load all example files\n",
    "example_data = {}\n",
    "for example_file in example_files:\n",
    "    with open(example_file, 'r') as f:\n",
    "        name = os.path.basename(example_file).replace('.json', '')\n",
    "        example_data[name] = json.load(f)\n",
    "\n",
    "# Analyze common fields\n",
    "def extract_fields(data, prefix=''):\n",
    "    fields = []\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            full_key = f\"{prefix}.{k}\" if prefix else k\n",
    "            if isinstance(v, (dict, list)):\n",
    "                fields.extend(extract_fields(v, full_key))\n",
    "            else:\n",
    "                fields.append(full_key)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            fields.extend(extract_fields(item, prefix))\n",
    "    return fields\n",
    "\n",
    "# Get common fields across all examples\n",
    "all_fields = {}\n",
    "for name, data in example_data.items():\n",
    "    all_fields[name] = set(extract_fields(data))\n",
    "\n",
    "# Find fields that appear in most examples\n",
    "common_fields = set.intersection(*all_fields.values())\n",
    "print(\"Common fields across all examples:\")\n",
    "pprint(sorted(common_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26740160",
   "metadata": {},
   "source": [
    "## Data Transformation Patterns\n",
    "\n",
    "From analyzing the examples, we can identify several key data transformation patterns:\n",
    "\n",
    "1. Nested structure flattening\n",
    "2. Date/time handling\n",
    "3. Currency conversions\n",
    "4. Calculated fields\n",
    "5. Reference data lookups\n",
    "\n",
    "Let's implement some common transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example transformations for FIRE data\n",
    "\n",
    "def flatten_fire_record(record):\n",
    "    \"\"\"Flatten nested FIRE JSON structures\"\"\"\n",
    "    flat_data = {}\n",
    "    \n",
    "    def flatten(data, prefix=''):\n",
    "        if isinstance(data, dict):\n",
    "            for k, v in data.items():\n",
    "                key = f\"{prefix}.{k}\" if prefix else k\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    flatten(v, key)\n",
    "                else:\n",
    "                    flat_data[key] = v\n",
    "        elif isinstance(data, list):\n",
    "            for i, item in enumerate(data):\n",
    "                flatten(item, f\"{prefix}[{i}]\")\n",
    "    \n",
    "    flatten(record)\n",
    "    return flat_data\n",
    "\n",
    "# Example transformation pipeline\n",
    "def transform_fire_record(record):\n",
    "    # 1. Flatten structure\n",
    "    flat = flatten_fire_record(record)\n",
    "    \n",
    "    # 2. Convert dates to datetime\n",
    "    for k, v in flat.items():\n",
    "        if isinstance(v, str) and ('date' in k.lower() or 'time' in k.lower()):\n",
    "            try:\n",
    "                flat[k] = pd.to_datetime(v)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # 3. Currency normalization (example)\n",
    "    amount_fields = [k for k in flat.keys() if 'amount' in k.lower()]\n",
    "    for field in amount_fields:\n",
    "        if isinstance(flat.get(field), (int, float)):\n",
    "            currency = flat.get(f\"{field.rsplit('.', 1)[0]}.currency\", 'USD')\n",
    "            # Here you would apply currency conversion as needed\n",
    "            \n",
    "    return flat\n",
    "\n",
    "# Apply transformations to an example\n",
    "example_name = next(iter(example_data.keys()))\n",
    "transformed = transform_fire_record(example_data[example_name])\n",
    "print(f\"Transformed fields from {example_name}:\")\n",
    "pprint({k: v for k, v in transformed.items() if pd.notnull(v)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95f400",
   "metadata": {},
   "source": [
    "## Data Ingestion Patterns\n",
    "\n",
    "FIRE data can be ingested in several ways:\n",
    "\n",
    "1. Direct JSON ingestion\n",
    "2. CSV/Tabular format (after flattening)\n",
    "3. Database loading\n",
    "4. Streaming ingestion\n",
    "\n",
    "Let's implement some common ingestion patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f337a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ingestion patterns\n",
    "\n",
    "# 1. Batch JSON ingestion\n",
    "def ingest_fire_json_batch(file_paths):\n",
    "    records = []\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            record = json.load(f)\n",
    "            transformed = transform_fire_record(record)\n",
    "            records.append(transformed)\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "# Create DataFrame from all examples\n",
    "df = ingest_fire_json_batch(examples)\n",
    "print(\"\\nDataFrame shape:\", df.shape)\n",
    "print(\"\\nColumns:\", sorted(df.columns))\n",
    "\n",
    "# 2. Example CSV export (for systems that prefer tabular format)\n",
    "csv_path = 'fire_data.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nExported to {csv_path}\")\n",
    "\n",
    "# 3. Database ingestion example (using SQLite for demonstration)\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "def create_fire_table(conn):\n",
    "    \"\"\"Create a table with common FIRE fields\"\"\"\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS fire_data (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        type TEXT,\n",
    "        date_created TIMESTAMP,\n",
    "        currency TEXT,\n",
    "        amount REAL,\n",
    "        raw_data JSON\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "def ingest_to_db(records, db_path=':memory:'):\n",
    "    \"\"\"Ingest FIRE records to SQLite database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    create_fire_table(conn)\n",
    "    \n",
    "    for record in records:\n",
    "        # Extract key fields\n",
    "        data = {\n",
    "            'id': record.get('id', str(hash(str(record)))),\n",
    "            'type': record.get('type'),\n",
    "            'date_created': datetime.now().isoformat(),\n",
    "            'currency': record.get('currency'),\n",
    "            'amount': record.get('amount'),\n",
    "            'raw_data': json.dumps(record)\n",
    "        }\n",
    "        \n",
    "        # Insert into database\n",
    "        placeholders = ', '.join(['?' for _ in data])\n",
    "        cols = ', '.join(data.keys())\n",
    "        sql = f'INSERT INTO fire_data ({cols}) VALUES ({placeholders})'\n",
    "        conn.execute(sql, list(data.values()))\n",
    "    \n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Example database ingestion\n",
    "conn = ingest_to_db(example_data.values())\n",
    "cursor = conn.execute('SELECT * FROM fire_data LIMIT 5')\n",
    "print(\"\\nSample database records:\")\n",
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49245c",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "From our analysis of FIRE examples, we can conclude:\n",
    "\n",
    "1. Data Structure Patterns:\n",
    "   - Hierarchical JSON structure with consistent top-level fields\n",
    "   - Common fields across all records (id, type, date_created, etc.)\n",
    "   - Nested objects for complex financial instruments\n",
    "   - Arrays for multiple related items\n",
    "\n",
    "2. Data Transformation Best Practices:\n",
    "   - Flatten nested structures for easier processing\n",
    "   - Convert dates to proper datetime objects\n",
    "   - Normalize currencies and amounts\n",
    "   - Preserve raw data alongside transformed data\n",
    "   - Validate against JSON schemas\n",
    "\n",
    "3. Data Ingestion Recommendations:\n",
    "   - Use batch processing for large datasets\n",
    "   - Maintain both raw and transformed data\n",
    "   - Index key fields for efficient querying\n",
    "   - Implement proper error handling and validation\n",
    "   - Consider both SQL and NoSQL storage options\n",
    "\n",
    "4. Implementation Tips:\n",
    "   - Use pandas for data manipulation\n",
    "   - Implement proper data validation\n",
    "   - Handle currency conversions carefully\n",
    "   - Maintain data lineage\n",
    "   - Log all transformations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
